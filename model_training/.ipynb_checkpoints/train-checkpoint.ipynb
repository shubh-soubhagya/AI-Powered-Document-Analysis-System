{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\suman\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\suman\\AppData\\Local\\Temp\\ipykernel_6184\\748844837.py\", line 1, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\suman\\anaconda3\\lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Example\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\compat.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m pickle \u001b[38;5;241m=\u001b[39m pickle\n\u001b[0;32m     42\u001b[0m copy_reg \u001b[38;5;241m=\u001b[39m copy_reg\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     CupyOps,\n\u001b[0;32m      3\u001b[0m     MPSOps,\n\u001b[0;32m      4\u001b[0m     NumpyOps,\n\u001b[0;32m      5\u001b[0m     Ops,\n\u001b[0;32m      6\u001b[0m     get_current_ops,\n\u001b[0;32m      7\u001b[0m     get_ops,\n\u001b[0;32m      8\u001b[0m     set_current_ops,\n\u001b[0;32m      9\u001b[0m     set_gpu_allocator,\n\u001b[0;32m     10\u001b[0m     use_ops,\n\u001b[0;32m     11\u001b[0m     use_pytorch_for_gpu_memory,\n\u001b[0;32m     12\u001b[0m     use_tensorflow_for_gpu_memory,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_mxnet, enable_tensorflow, has_cupy\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\backends\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cupy_allocators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy_pytorch_allocator, cupy_tensorflow_allocator\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_server\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamServer\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcupy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CupyOps\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MPSOps\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\backends\\cupy_ops.py:16\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     is_cupy_array,\n\u001b[0;32m      8\u001b[0m     is_mxnet_gpu_array,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     torch2xp,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _custom_kernels\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@registry\u001b[39m\u001b[38;5;241m.\u001b[39mops(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCupyOps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCupyOps\u001b[39;00m(Ops):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\backends\\numpy_ops.pyx:1\u001b[0m, in \u001b[0;36minit thinc.backends.numpy_ops\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"..\\data\\train\\merged_train_sentences.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The stock market experienced a significant ris...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investing in mutual funds can be a good way to...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Federal Reserve announced an increase in i...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptocurrencies like Bitcoin are highly volat...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's important to have an emergency fund cover...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences   Category\n",
       "0  The stock market experienced a significant ris...  financial\n",
       "1  Investing in mutual funds can be a good way to...  financial\n",
       "2  The Federal Reserve announced an increase in i...  financial\n",
       "3  Cryptocurrencies like Bitcoin are highly volat...  financial\n",
       "4  It's important to have an emergency fund cover...  financial"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The stock market experienced a significant ris...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investing in mutual funds can be a good way to...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Federal Reserve announced an increase in i...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptocurrencies like Bitcoin are highly volat...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's important to have an emergency fund cover...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>The parties agree to seek a mediator to assist...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>The vendor must comply with all relevant produ...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>The user must notify the company of any issues...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>The company reserves the right to adjust its p...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>The client is responsible for ensuring the acc...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentences   Category\n",
       "0    The stock market experienced a significant ris...  financial\n",
       "1    Investing in mutual funds can be a good way to...  financial\n",
       "2    The Federal Reserve announced an increase in i...  financial\n",
       "3    Cryptocurrencies like Bitcoin are highly volat...  financial\n",
       "4    It's important to have an emergency fund cover...  financial\n",
       "..                                                 ...        ...\n",
       "474  The parties agree to seek a mediator to assist...      legal\n",
       "475  The vendor must comply with all relevant produ...      legal\n",
       "476  The user must notify the company of any issues...      legal\n",
       "477  The company reserves the right to adjust its p...      legal\n",
       "478  The client is responsible for ensuring the acc...      legal\n",
       "\n",
       "[479 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('ï»¿', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {'healthcare': 0, 'financial': 1, 'legal': 2}\n",
    "df['Category'] = df['Category'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_data['Sentences'].tolist()\n",
    "train_labels = train_data['Category'].tolist()\n",
    "\n",
    "test_texts = test_data['Sentences'].tolist()\n",
    "test_labels = test_data['Category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0, 1, 2]\n",
    "for category in categories:\n",
    "    textcat.add_label(str(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spacy = []\n",
    "for text, label in zip(train_texts, train_labels):\n",
    "    cats = {str(cat): label == cat for cat in categories}\n",
    "    train_data_spacy.append((text, {\"cats\": cats}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Losses {'textcat': 15.53426352594397}\n",
      "Iteration 2: Losses {'textcat': 4.653038211175954}\n",
      "Iteration 3: Losses {'textcat': 1.0417724006226114}\n",
      "Iteration 4: Losses {'textcat': 0.5893221140246774}\n",
      "Iteration 5: Losses {'textcat': 0.0005196181831224785}\n",
      "Iteration 6: Losses {'textcat': 0.19651278397270425}\n",
      "Iteration 7: Losses {'textcat': 0.006236630314785609}\n",
      "Iteration 8: Losses {'textcat': 0.10219073613012833}\n",
      "Iteration 9: Losses {'textcat': 0.000425344640231365}\n",
      "Iteration 10: Losses {'textcat': 0.005869759906665254}\n"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        random.shuffle(train_data_spacy)\n",
    "        batches = minibatch(train_data_spacy, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            examples = [Example.from_dict(nlp.make_doc(text), annotation) for text, annotation in zip(texts, annotations)]\n",
    "            nlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)\n",
    "        print(f\"Iteration {i+1}: Losses {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ..\\model_training\\trained_model\n"
     ]
    }
   ],
   "source": [
    "output_dir = r\"..\\model_training\\trained_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest confidence\n",
    "    predicted_labels.append(int(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  healthcare       0.88      1.00      0.93        21\n",
      "   financial       1.00      0.86      0.93        29\n",
      "       legal       0.96      0.98      0.97        46\n",
      "\n",
      "    accuracy                           0.95        96\n",
      "   macro avg       0.94      0.95      0.94        96\n",
      "weighted avg       0.95      0.95      0.95        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, target_names=['healthcare', 'financial', 'legal'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[21  0  0]\n",
      " [ 2 25  2]\n",
      " [ 1  0 45]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels, predicted_labels, labels=categories)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = r'..\\data\\train\\merged_train_sentences.csv'  # Update with actual test CSV file path\n",
    "test_df = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df['Sentences'].tolist()\n",
    "test_labels = test_df['Category'].map(category_mapping).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest confidence\n",
    "    predicted_labels.append(int(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  healthcare       0.98      1.00      0.99       129\n",
      "   financial       1.00      0.97      0.98       126\n",
      "       legal       0.99      1.00      0.99       224\n",
      "\n",
      "    accuracy                           0.99       479\n",
      "   macro avg       0.99      0.99      0.99       479\n",
      "weighted avg       0.99      0.99      0.99       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, target_names=['healthcare', 'financial', 'legal'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[129   0   0]\n",
      " [  2 122   2]\n",
      " [  1   0 223]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels, predicted_labels, labels=categories)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path2 = r'..\\data\\test\\output.csv'  # Update with actual test CSV file path\n",
    "test_df2 = pd.read_csv(test_csv_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df['Sentences'].tolist()\n",
    "test_labels = test_df['Category'].map(category_mapping).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest confidence\n",
    "    predicted_labels.append(int(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  healthcare       0.98      1.00      0.99       129\n",
      "   financial       1.00      0.97      0.98       126\n",
      "       legal       0.99      1.00      0.99       224\n",
      "\n",
      "    accuracy                           0.99       479\n",
      "   macro avg       0.99      0.99      0.99       479\n",
      "weighted avg       0.99      0.99      0.99       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, target_names=['healthcare', 'financial', 'legal'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
