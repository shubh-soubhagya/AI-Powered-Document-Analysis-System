{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"..\\data\\train\\merged_train_sentences.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The stock market experienced a significant ris...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investing in mutual funds can be a good way to...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Federal Reserve announced an increase in i...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptocurrencies like Bitcoin are highly volat...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's important to have an emergency fund cover...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences   Category\n",
       "0  The stock market experienced a significant ris...  financial\n",
       "1  Investing in mutual funds can be a good way to...  financial\n",
       "2  The Federal Reserve announced an increase in i...  financial\n",
       "3  Cryptocurrencies like Bitcoin are highly volat...  financial\n",
       "4  It's important to have an emergency fund cover...  financial"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The stock market experienced a significant ris...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investing in mutual funds can be a good way to...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Federal Reserve announced an increase in i...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptocurrencies like Bitcoin are highly volat...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's important to have an emergency fund cover...</td>\n",
       "      <td>financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>The parties agree to seek a mediator to assist...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>The vendor must comply with all relevant produ...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>The user must notify the company of any issues...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>The company reserves the right to adjust its p...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>The client is responsible for ensuring the acc...</td>\n",
       "      <td>legal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentences   Category\n",
       "0    The stock market experienced a significant ris...  financial\n",
       "1    Investing in mutual funds can be a good way to...  financial\n",
       "2    The Federal Reserve announced an increase in i...  financial\n",
       "3    Cryptocurrencies like Bitcoin are highly volat...  financial\n",
       "4    It's important to have an emergency fund cover...  financial\n",
       "..                                                 ...        ...\n",
       "474  The parties agree to seek a mediator to assist...      legal\n",
       "475  The vendor must comply with all relevant produ...      legal\n",
       "476  The user must notify the company of any issues...      legal\n",
       "477  The company reserves the right to adjust its p...      legal\n",
       "478  The client is responsible for ensuring the acc...      legal\n",
       "\n",
       "[479 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('ï»¿', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {'healthcare': 0, 'financial': 1, 'legal': 2}\n",
    "df['Category'] = df['Category'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_data['Sentences'].tolist()\n",
    "train_labels = train_data['Category'].tolist()\n",
    "\n",
    "test_texts = test_data['Sentences'].tolist()\n",
    "test_labels = test_data['Category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0, 1, 2]\n",
    "for category in categories:\n",
    "    textcat.add_label(str(category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_spacy = []\n",
    "for text, label in zip(train_texts, train_labels):\n",
    "    cats = {str(cat): label == cat for cat in categories}\n",
    "    train_data_spacy.append((text, {\"cats\": cats}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Losses {'textcat': 14.068121591117233}\n",
      "Iteration 2: Losses {'textcat': 2.06164030356188}\n",
      "Iteration 3: Losses {'textcat': 0.40877229757182065}\n",
      "Iteration 4: Losses {'textcat': 0.19052461730114004}\n",
      "Iteration 5: Losses {'textcat': 0.03578620367924286}\n",
      "Iteration 6: Losses {'textcat': 0.0014454251210080128}\n",
      "Iteration 7: Losses {'textcat': 0.0016560616664038266}\n",
      "Iteration 8: Losses {'textcat': 7.025966226416498e-06}\n",
      "Iteration 9: Losses {'textcat': 7.657258302988371e-06}\n",
      "Iteration 10: Losses {'textcat': 9.873587486836175e-06}\n"
     ]
    }
   ],
   "source": [
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        random.shuffle(train_data_spacy)\n",
    "        batches = minibatch(train_data_spacy, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            examples = [Example.from_dict(nlp.make_doc(text), annotation) for text, annotation in zip(texts, annotations)]\n",
    "            nlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)\n",
    "        print(f\"Iteration {i+1}: Losses {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ..\\model_training\\trained_model\n"
     ]
    }
   ],
   "source": [
    "output_dir = r\"..\\model_training\\trained_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest confidence\n",
    "    predicted_labels.append(int(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  healthcare       0.95      1.00      0.98        21\n",
      "   financial       1.00      0.90      0.95        29\n",
      "       legal       0.96      1.00      0.98        46\n",
      "\n",
      "    accuracy                           0.97        96\n",
      "   macro avg       0.97      0.97      0.97        96\n",
      "weighted avg       0.97      0.97      0.97        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, target_names=['healthcare', 'financial', 'legal'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[21  0  0]\n",
      " [ 1 26  2]\n",
      " [ 0  0 46]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels, predicted_labels, labels=categories)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = r'..\\data\\train\\merged_train_sentences.csv'  # Update with actual test CSV file path\n",
    "test_df = pd.read_csv(test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df['Sentences'].tolist()\n",
    "test_labels = test_df['Category'].map(category_mapping).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest confidence\n",
    "    predicted_labels.append(int(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  healthcare       0.99      1.00      1.00       129\n",
      "   financial       1.00      0.98      0.99       126\n",
      "       legal       0.99      1.00      1.00       224\n",
      "\n",
      "    accuracy                           0.99       479\n",
      "   macro avg       0.99      0.99      0.99       479\n",
      "weighted avg       0.99      0.99      0.99       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, target_names=['healthcare', 'financial', 'legal'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[129   0   0]\n",
      " [  1 123   2]\n",
      " [  0   0 224]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels, predicted_labels, labels=categories)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path2 = r'..\\data\\test\\output.csv'  # Update with actual test CSV file path\n",
    "test_df2 = pd.read_csv(test_csv_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df['Sentences'].tolist()\n",
    "test_labels = test_df['Category'].map(category_mapping).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    predicted_label = max(doc.cats, key=doc.cats.get)  # Get the label with the highest confidence\n",
    "    predicted_labels.append(int(predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  healthcare       0.99      1.00      1.00       129\n",
      "   financial       1.00      0.98      0.99       126\n",
      "       legal       0.99      1.00      1.00       224\n",
      "\n",
      "    accuracy                           0.99       479\n",
      "   macro avg       0.99      0.99      0.99       479\n",
      "weighted avg       0.99      0.99      0.99       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, predicted_labels, target_names=['healthcare', 'financial', 'legal'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
